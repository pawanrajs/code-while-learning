{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# %load find_signature.py\r\n",
    "#!/usr/bin/python3\r\n",
    "\r\n",
    "import joblib\r\n",
    "import numpy\r\n",
    "numpy.random.seed(42)\r\n",
    "\r\n",
    "\r\n",
    "### The words (features) and authors (labels), already largely processed.\r\n",
    "### These files should have been created from the previous (Lesson 10)\r\n",
    "### mini-project.\r\n",
    "words_file = \"../text_learning/your_word_data.pkl\" \r\n",
    "authors_file = \"../text_learning/your_email_authors.pkl\"\r\n",
    "word_data = joblib.load( open(words_file, \"rb\"))\r\n",
    "authors = joblib.load( open(authors_file, \"rb\") )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "\r\n",
    "\r\n",
    "### test_size is the percentage of events assigned to the test set \r\n",
    "### (the remainder go into training)\r\n",
    "### feature matrices changed to dense representations for compatibility with\r\n",
    "### classifier functions in versions 0.15.2 and earlier\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "features_train, features_test, labels_train, labels_test = \\\r\n",
    "    train_test_split(word_data, authors, test_size=0.1, random_state=42)\r\n",
    "\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\r\n",
    "features_train = vectorizer.fit_transform(features_train)\r\n",
    "features_test  = vectorizer.transform(features_test).toarray()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "print(features_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15820, 37861)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "### a classic way to overfit is to use a small number\r\n",
    "### of data points and a large number of features;\r\n",
    "### train on only 150 events to put ourselves in this regime\r\n",
    "features_train = features_train[:150].toarray()\r\n",
    "labels_train   = labels_train[:150]\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "### your code goes here\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "dt_less_features = DecisionTreeClassifier()\r\n",
    "dt_less_features.fit(features_train, labels_train)\r\n",
    "accuracy_overfit = dt_less_features.score(features_test, labels_test)\r\n",
    "print(accuracy_overfit)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8168373151308305\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "### Take your (overfit) decision tree and use the feature_importances_ attribute to get \r\n",
    "### a list of the relative importance of all the features being used. \r\n",
    "### We suggest only printing out the feature importance if it’s above (0.2). \r\n",
    "### What’s the importance of the most important feature? What is the number of this feature?\r\n",
    "all_feature_importances = dt_less_features.feature_importances_\r\n",
    "print([(f, i) for i, f in enumerate(all_feature_importances) if f >= 0.2])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0.36363636363636365, 21323)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "### In order to figure out what words are causing the problem, you need to go back to the TfIdf and \r\n",
    "### use the feature numbers that you obtained in the previous part of the mini-project to get the associated words. \r\n",
    "### You can return a list of all the words in the TfIdf by calling get_feature_names() on it; \r\n",
    "### Pull out the word that’s causing most of the discrimination of the decision tree. \r\n",
    "### What is it? Does it make sense as a word that’s uniquely tied to either Chris Germany or Sara Shackleton, a signature of sorts?\r\n",
    "\r\n",
    "all_words = vectorizer.get_feature_names()\r\n",
    "print(all_words[21323])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "houectect\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# This word seems like an outlier in a certain sense, so let’s remove it and refit. \r\n",
    "# Go back to text_learning/vectorize_text.py, and remove this word from the emails \r\n",
    "# using the same method you used to remove “sara”, “chris”, etc. \r\n",
    "# Rerun vectorize_text.py, and once that finishes, rerun find_signature.py. \r\n",
    "# Any other outliers pop up? What word is it?"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('.udacityml')"
  },
  "interpreter": {
   "hash": "a2d73c167f3de0bf816883dd1ae4d86285b5daa4d07776b66669f5cd19114848"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}